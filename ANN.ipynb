{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN: Fully connected Neural Networks\n",
    "- Hands-on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required libraries\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from torchvision.datasets import MNIST\n",
    "from torch import optim\n",
    "from torch import max as MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784 # 28X28 image\n",
    "hidden_size = [124, 64]\n",
    "output_size = 10\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_size[0]), \n",
    "                      nn.ReLU(), \n",
    "                      nn.Linear(hidden_size[0], hidden_size[1]), \n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_size[1], output_size),\n",
    "                      nn.LogSoftmax(dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=124, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=124, out_features=64, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "tranform_ori = transforms.Compose([transforms.ToTensor(), \n",
    "                                  transforms.Normalize([0.5, ], [0.5, ])\n",
    "                                  ])\n",
    "train_set = MNIST('MNIST_data', download = True,\n",
    "                  train = True, transform = tranform_ori )\n",
    "test_set = MNIST('MNIST_data', download = True,\n",
    "                  train = False, transform = tranform_ori )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset\n",
    "trainloader = DataLoader(train_set, batch_size = 64, \n",
    "                         shuffle = True)\n",
    "testloader = DataLoader(test_set, batch_size = 64, \n",
    "                         shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.003)\n",
    "epochs = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at 0 is 0.2947546274724927\n",
      "Loss at 1 is 0.2860550588842775\n",
      "Loss at 2 is 0.2779385609937502\n",
      "Loss at 3 is 0.2702988602522848\n",
      "Loss at 4 is 0.2631594647826162\n"
     ]
    }
   ],
   "source": [
    "## Model building\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = cost(output, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    print(f\"Loss at {epoch} is {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Accuracy Score is  89.81886942675159\n"
     ]
    }
   ],
   "source": [
    "# Predict and Evaluate\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy  = 0\n",
    "no_iter = 0\n",
    "for images, labels in testloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        output = model(images)\n",
    "        _, predicted_tensor = MAX(output, 1)\n",
    "        pred = np.squeeze(predicted_tensor.numpy())\n",
    "        true = np.squeeze(labels.numpy())\n",
    "        accuracy += accuracy_score(pred, true)\n",
    "        no_iter += 1\n",
    "print(\"Accuracy Score is \", accuracy/no_iter*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
